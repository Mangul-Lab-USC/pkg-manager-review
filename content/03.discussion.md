## Discussion {.page_break_before}

### Existing problems with software distribution and installation

The installation process of bioinformatics research software is typically a multi-step process, starting with the end-user locating and downloading the software.
Next is the actual installation, during which the end-user must determine what dependencies are missing and resolve them by installing the required software[5](https://paperpile.com/c/4vBDtY/kjwlC).
Even in cases where the end-user is familiar with this process, they are typically installing on high-performance clusters where they are constrained by user-level permissions that prevent them from following standard installation procedures.



- root access limitations
- reproducibility of findings
- version conflicts
- dependency resolution

### Definitions and explanations of distribution system types

#### Package Managers

Package managers appeared nearly thirty years ago as software developers sought to automate and standardize the software installation process.
The earliest package managers (e.g. APT and RPM) were built into Linux operating systems and lacked now common features like dependency resolution.
Modern package managers are available for all major operating systems, with both integrated and user-installed options available.
Some are package managers are limited to software written in a specific programming language (e.g. pip distributes software written in Python), while others are limited to sofware with a particular purpose (e.g. Bioconda distributes omics software).

Every package managers uses its own package format, which follows the general structure shown in Figure @fig:package-schematic.

![
**Schematic showing standard package contents.**
Though the exact contents varies between different package formats, all include the software and relevant metadata necessary to complete installation.
](images/package_schematic.png){#fig:package-schematic}

The metadata gives the package manager the necessary information to install the packaged software.

To use a package manager, a user instructs the package manager to install software, then the package manager performs all the necessary steps to install the software as shown in Figure @fig:package-manager-usage.
Assuming the software is not already installed, the package manager retrieves the appropriate package from the repository, a server that stores all of the available packages.
The package manager then uses the package's metadata to determine what it needs to do to complete installation.
For most packages, this includes verifying the installation of all dependencies, which are other pieces of software that must be installed prior to the initial software being installed.

![
**Standard workflow for installing software via a package manager.**
The user, usually an admin, asks the package manager to install a specific piece of software. If the software is not already installed, the package manager fetches the approrpriate package from the repository. If any of the dependencies are not already installed, the package manager "loops" through the missing dependencies. Once all dependencies are installed, the original software is installed.
](images/package_manager_usage.png){#fig:package-manager-usage width="6in"}

The package manager verifies each dependency by confirming that the dependency is already installed or installing the dependency if it is missing.
For missing dependencies, the package manager retrieves the dependency's package from the repository and starts the installation procedure for that package.
Once all the dependencies are installed, the initially requested software is installed.
However, the package manager often goes through several iterations of this process because every dependency can have it's own list of dependencies, in which case each of the dependency's dependencies must be verified through the same process.

In most cases, a package manager is able to install all of the missing dependencies, but there are two relatively common problems that a package manager cannot overcome.
The first is circular dependencies, which occurs when software A has a dependency on software B and software B has a dependency on software A.
A package manager cannot install A without installing B first, but B cannot be installed without installing A first.
The second is conflicting versions, which occurs when software A and software B have the same dependency, but require different versions.
Package managers only allow one version of software to be installed at a time, preventing both A and B from having their depedencies met simultaneously.

Administrators often block users from installing software to prevent unwanted changes to both the operating system and existing sofware. This includes blocking access to package managers built into the operating system, as well as preventing users from installing their own.


  - benefits for the developer
    - mature technology - higher degree of familiarity
    - allows dependency specification (including versions)
    -limitations for the developer
    - can't always use to install missing dependencies for end-user
  - benefits for the end-user
    - package size is minimal (dependencies aren't duplicated)
    - installs missing dependencies
  - limitations for the end-user
    - not always accessible (unless admin user)
    - can't install multiple versions of same software

#### Containerization and Virtualization

One approach to sharing software involves virtualization.
Virtualization is a technique that allows the creation of instances of a software environment, often called 'images'.
These images present many benefits for software sharing: only a single image file needs to be downloaded by users, and these image files can have all necessary dependencies for the software pre-installed by the developer, thereby avoiding installation difficulties for users.

Traditional virtual machines emulate operating systems and are run directly on the host's hardware.
These are sometimes known as 'type 1 hypervisors' [@Nathan-1].
Later, 'type 2' virtualization techniques were developed, running on top of the host operating system (OS) by translating all OS instructions within the guest image [@Nathan-1].
While these approaches excel in portability, they incur a significant CPU and memory overhead, prompting the development of a more recent approach called Operating System (OS)-Level Virtualization.
OS-Level Virtualization runs on top of the same kernel as the host OS, allowing multiple isolated user spaces to be run in parallel and incurring lower CPU, memory, and networking overhead [@Nathan-1,@Nathan-2].
These user spaces, e.g. OS-level images being executed by users, are often called "containers", but also go by a variety of other names.
Examples of this technique include Docker [@Nathan-3], LXC [@Nathan-4], OpenVZ [@Nathan-5], Linux-VServer [@Nathan-6], and rkt [@Nathan-7].

Of these, Docker is perhaps the most widely-used platform.
A key aspect of the Docker approach is its modularity: images are stored in a public repository on Docker's website, and it is easy to use an existing image as a "base" to build a new image off of.
Docker images are defined by a human-readable, plaintext "Dockerfile" in which the developer specifies whether to build off of a previous base docker image and what additional software libraries and dependencies should be installed.
The Dockerfile also serves as an easy-to-read documentation of what dependencies the software is built on [@Nathan-8].
Docker then builds an image based on the developerâ€™s specifications and this image can be uploaded to the Docker website.

Several limitations exist with Docker and other OS-level virtualization platforms.
OS-level images are, as the name implies, limited to a specific host operating system [@Nathan-1,@Nathan-8].
Security concerns have been raised about the vulnerability of containers to compromise, denial of service, and privilege escalation attacks [@Nathan-2].
Deployment on high-performance computing clusters is a promising possibility but presents substantial engineering challenges having to do with maximizing resource utilization and allocating resources effectively [@Nathan-9].

![
**Schematic showing standard containerization objects.**
](images/containerization_schematics.png){#fig:containerization-schematics width="6in"}

![
**Running containerized software**
](images/container_usage.png){#fig:container_usage width="6in"}

  - benefits for the developer
    - include specific versions of dependencies
    - known running environment
      - fewer test variables
      - reproducibility of results
  - limitations for the developer
    - learn a new system instead of focusing on research
  - benefits for the end-user
    - no installation (except possible runtime)
    - no dependency issues
    - sandbox provides computer system security
  - limitations for the end-user
    - container size
    - duplication of dependencies
    - root access requirement to install runtime
    - configuration in cluster
- centralized repositories
  - definition
    - channels
  - benefits
    - known download site
    - hosting is taken of
  - limitations
    - repo specific restrictions

![
**Relative popularity of package managers.**
According to Google Trends, general use package managers have at least ten times the popularity of their omics-only counterparts, which is expected when their limited-use is taken into account.
Docker, the most popular containerization software is nearly five times as popular as the most popular package manager, indicating a software industry in <location> trend towards containerization over the past <time period>.
](images/trends.png){#fig:google-trends-chart width="6in"}

![
**Usage of package managers in academia based on citations.**
](images/citations.png){#fig:citations-chart width="6in"}

![
**Usage of package managers in academia based on Google Scholar Results.**
](images/google_scholar_results.png){#fig:google-scholar-chart width="6in"}

![
**Total number of packages.**
](images/total_number_of_packages.png){#fig:available-packages-chart width="6in"}

![
**Packages heatmap**
](images/tools_heatmap.png){#fig:available-packages-heatmap width="6in"}

![
**Overlap in available packages between omics package managers.**
](images/overlap_in_tools.png){#fig:overlap-in-tools width="6in"}

![
**Availablity of Bioconda's packages in non-omics package managers.**
](images/tools_shared_with_bioconda.png){#fig:bioconda-packages-availability-chart width="6in"}

![
**Availablity of Bioinformatics Tools' packages in non-omics package managers.**
](images/tools_shared_with_biotools.png){#fig:biotools-packages-availability-chart width="6in"}

![
**Availability of omicX's packages in non-omics package managers.**
](images/tools_shared_with_omicX.png){#fig:omicX-packages-availability-chart width="6in"}
